import cv2
model=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
#to send email
import smtplib
def email( ):
    s = smtplib.SMTP('smtp.gmail.com', 587)
    s.starttls()
    s.login("ambrunimurali2000@gmail.com", "123abcd789")
    message = "this photo is of ambruni"
    s.sendmail("ambrunimurali2000@gmail.com", "ambrunimurali2000@gmail.com", message)
    s.quit()
 
 # FOR WHATSAPP
 from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
import time
    driver = webdriver.Chrome('/Users/pmurali/chromedriver')
  
driver.get("https://web.whatsapp.com/")
wait = WebDriverWait(driver, 600)
  

target = '"AMBRUNI "'
  
# Replace the below string with your own message
string = "HELLO AMBRUNI HERE"
  
x_arg = '//span[contains(@title,' + target + ')]'
group_title = wait.until(EC.presence_of_element_located((
    By.XPATH, x_arg)))
group_title.click()
inp_xpath = '//div[@class="input"][@dir="auto"][@data-tab="1"]'
input_box = wait.until(EC.presence_of_element_located((
    By.XPATH, inp_xpath)))
for i in range(100):
    input_box.send_keys(string + Keys.ENTER)
    time.sleep(1)


cap=cv2.VideoCapture(0)
x=False
while True:
    ret,photo= cap.read()

    face=model.detectMultiScale(photo)
    if len(face)==0:
        pass
    else:
        x1=face[0][0]
        y1=face[0][1]
        x2= x1+face[0][2]
        y2= y1+face[0][3]

        p=cv2.rectangle(photo,(x1,y1),(x2,y2),[0,255,0],5)
        cv2.imshow('video',p)
        if cv2.waitKey(100)==13:
            cap.release()
            break
        x=False   
        
cv2.destroyAllWindows()

if x==True:
    whatsapp()
    email()
    
    
   # COLLECTING DATASET
   
   import cv2
import numpy as np

# Load HAAR face classifier
face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

# Load functions
def face_extractor(img):
    # Function detects faces and returns the cropped face
    # If no face detected, it returns the input image
    
    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(img, 1.3, 5)
    
    if faces is ():
        return None
    
    # Crop all faces found
    for (x,y,w,h) in faces:
        x=x-10
        y=y-10
        cropped_face = img[y:y+h+50, x:x+w+50]

    return cropped_face

# Initialize Webcam
cap = cv2.VideoCapture(0)
count = 0

# Collect 100 samples of your face from webcam input
while True:

    ret, frame = cap.read()
    if face_extractor(frame) is not None:
        count += 1
        face = cv2.resize(face_extractor(frame), (400, 400))
        #face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)

        # Save file in specified directory with unique name
        file_name_path = '/Users/pmurali/Desktop/chromedriver_mac64' + str(count) + '.jpg'
        cv2.imwrite(file_name_path, face)

        # Put count on images and display live count
        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)
        cv2.imshow('Face Cropper', face)
        
    else:
        print("Face not found")
        pass

    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key
        break
        
cap.release()
cv2.destroyAllWindows()      
print("Collecting Samples Complete")


#TRAINING AND DETECTING FACE
from PIL import Image
from keras.applications.vgg16 import preprocess_input
import base64
from io import BytesIO
import json
import random
import cv2
from keras.models import load_model
import numpy as np

from keras.preprocessing import image
model = load_model('facefeatures_new_model_final.h5')

# Loading the cascades
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

def face_extractor(img):
    # Function detects faces and returns the cropped face
    # If no face detected, it returns the input image
    
    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(img, 1.3, 5)
    
    if faces is ():
        return None
    
    # Crop all faces found
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)
        cropped_face = img[y:y+h, x:x+w]

    return cropped_face

# Doing some Face Recognition with the webcam
video_capture = cv2.VideoCapture(0)
while True:
    _, frame = video_capture.read()
    #canvas = detect(gray, frame)
    #image, face =face_detector(frame)
    
    face=face_extractor(frame)
    if type(face) is np.ndarray:
        face = cv2.resize(face, (224, 224))
        im = Image.fromarray(face, 'RGB')
           #Resizing into 128x128 because we trained the model with this image size.
        img_array = np.array(im)
                    #Our keras model used a 4D tensor, (images x height x width x channel)
                    #So changing dimension 128x128x3 into 1x128x128x3 
        img_array = np.expand_dims(img_array, axis=0)
        pred = model.predict(img_array)
        print(pred)
                     
        name="None matching"
        
        if(pred[0][3]>0.5):
            name='AMBRUNI'
        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)
    else:
        cv2.putText(frame,"No face found", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)
    cv2.imshow('Video', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
video_capture.release()
cv2.destroyAllWindows()

#AWS CLI

import time
import os
cap=cv2.VideoCapture(0)
detecta=False
detecto=False

while True:
    ret,photo= cap.read()

    face=model.detectMultiScale(photo)
    if len(face)==0:
        pass
    else:
        x1=face[0][0]
        y1=face[0][1]
        x2= x1+face[0][2]
        y2= y1+face[0][3]

        aphoto=cv2.rectangle(photo,(x1,y1),(x2,y2),[0,255,0],5)
        cv2.imshow('camera LIVE',aphoto)
        cropped_photo=photo[y1:y2,x1:x2]
        cropped_photo=cv2.resize(cropped_photo, (200,200))
        cropped_photo=cv2.cvtColor(cropped_photo, cv2.COLOR_BGR2GRAY)
        
        detection_result=amodel.predict(cropped_photo)
        
        
        if detection_result[1]<500:
            confidence = int( 100 * (1 - (detection_result[1])/400) )
            #display_string = str(confidence) + '% Confident it is tasha'
            
        if confidence>85:
            detecta=True
            cv2.putText(photo, "This is ambruni", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)
            cv2.imshow('face',photo)
            
        else:
            cv2.putText(photo, "This is NOT ambruni.Will create aws instance .", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)
            detecto=True
            cv2.imshow('face',photo)
        
        if cv2.waitKey(100)==13:
            cap.release()
            break
        
            
        
cv2.destroyAllWindows()

if detecta==True:
    cap.release()
    whatsapp()
    email()
    
if detecto==True:
    cap.release()
    cv2.destroyAllWindows()
    os.system("aws ec2 run-instances  --image-id ami-010aff33ed5991201 --instance-type t2.micro  --subnet-id subnet-ecf11a87  --count 1 --security-group-ids sg-0067e1de928834ac7   --key-name aws21")
    print("Instance Launched")
    print("Please wait for 2 minutes instance is initializing")
    os.system("aws ec2 create-volume --availability-zone ap-south-1a --size 5 --volume-type gp2 --tag-specification  ResourceType=volume,Tags=[{Key=face,Value=volume}]")
    print("Volume Created")
    i=input("Enter instance id : ")
    j=input("Enter volume id :")
    time.sleep(30)
    os.system("aws ec2 attach-volume --instance-id {} --volume-id {} --device /dev/sdk".format(i,j))
    print("Volume Successfully attached to the instance")
    
